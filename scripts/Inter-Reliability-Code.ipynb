{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22a0fddd-fa64-43d7-98a9-d627add4b594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Agreement by item (kappa + observed agreement) ===\n",
      "               Item  Cohens_Kappa  Observed_Agreement_%\n",
      "                 FS      1.000000            100.000000\n",
      "                 PE      0.945871             97.435897\n",
      "                  C      0.692375             88.461538\n",
      "                  U      0.656388             92.307692\n",
      "                  R      0.702290             88.461538\n",
      "                  S      0.961576             98.717949\n",
      "                  M      0.808260             93.589744\n",
      "                  P      0.469388             92.307692\n",
      "                 Q1      1.000000            100.000000\n",
      "                 Q2      0.000000             89.743590\n",
      "                 Q3      0.135662             57.692308\n",
      "                 Q4      0.383399             89.743590\n",
      "                 Q5      0.627151             87.179487\n",
      "                 Q6      0.304813             74.358974\n",
      "Overall_ISO_FS_to_P      0.848076             93.910256\n",
      "\n",
      "=== Overall ISO (FS–P) ===\n",
      "Cohen's kappa: 0.8480759620189905\n",
      "Observed agreement (%): 93.91\n",
      "\n",
      "Saved: output/agreement_results.csv\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Supplementary Material: Inter-rater Reliability (Cohen's Kappa + Observed Agreement)\n",
    "\n",
    "This script calculates inter-rater agreement between two reviewers.\n",
    "\n",
    "It computes:\n",
    "1) Cohen’s kappa for each binary coding item:\n",
    "   - ISO/IEC 25010 attributes: FS, PE, C, U, R, S, M, P\n",
    "   - Quality appraisal items: Q1–Q6\n",
    "2) Observed agreement (%) for each item\n",
    "3) An overall Cohen’s kappa and observed agreement across the ISO/IEC 25010 block (FS–P)\n",
    "   by pooling all ISO decisions across studies and attributes.\n",
    "\n",
    "Expected Excel columns:\n",
    "- PS_ID, Review_ID\n",
    "- ISO binary columns: FS, PE, C, U, R, S, M, P\n",
    "- QA binary columns: Q1, Q2, Q3, Q4, Q5, Q6\n",
    "- Review_ID contains exactly two values (e.g., \"R_1\" and \"R_2\").\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "# -----------------------\n",
    "# 1) Load extraction file\n",
    "# -----------------------\n",
    "FILE_PATH = \"SLR_PS1_78.xlsx\"   # <-- recommended repo path\n",
    "df = pd.read_excel(FILE_PATH)\n",
    "\n",
    "# -----------------------\n",
    "# 2) Configuration\n",
    "# -----------------------\n",
    "ISO_COLS = [\"FS\", \"PE\", \"C\", \"U\", \"R\", \"S\", \"M\", \"P\"]\n",
    "QAS_COLS = [\"Q1\", \"Q2\", \"Q3\", \"Q4\", \"Q5\", \"Q6\"]\n",
    "ALL_BINARY_COLS = ISO_COLS + QAS_COLS\n",
    "\n",
    "R1 = \"R_1\"\n",
    "R2 = \"R_2\"\n",
    "\n",
    "# -----------------------\n",
    "# 2.1) Basic checks\n",
    "# -----------------------\n",
    "required_cols = {\"PS_ID\", \"Review_ID\"} | set(ALL_BINARY_COLS)\n",
    "missing = required_cols - set(df.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing required columns in Excel file: {sorted(missing)}\")\n",
    "\n",
    "reviewers = set(df[\"Review_ID\"].dropna().unique())\n",
    "if not ({R1, R2} <= reviewers):\n",
    "    raise ValueError(f\"Expected reviewers '{R1}' and '{R2}' in Review_ID. Found: {sorted(reviewers)}\")\n",
    "\n",
    "# ------------------------------------------\n",
    "# 3) Agreement for a single binary column\n",
    "# ------------------------------------------\n",
    "def aligned_ratings(df: pd.DataFrame, col: str, r1: str = R1, r2: str = R2):\n",
    "    \"\"\"Return aligned ratings vectors for r1 and r2 for a given column.\"\"\"\n",
    "    piv = df.pivot(index=\"PS_ID\", columns=\"Review_ID\", values=col)\n",
    "    mask = piv[r1].notna() & piv[r2].notna()\n",
    "    y1 = piv.loc[mask, r1].astype(int)\n",
    "    y2 = piv.loc[mask, r2].astype(int)\n",
    "    return y1, y2\n",
    "\n",
    "def kappa_for_column(df: pd.DataFrame, col: str, r1: str = R1, r2: str = R2) -> float:\n",
    "    \"\"\"Cohen's kappa for one binary column.\"\"\"\n",
    "    y1, y2 = aligned_ratings(df, col, r1, r2)\n",
    "    if len(y1) == 0:\n",
    "        return np.nan\n",
    "    return cohen_kappa_score(y1, y2)\n",
    "\n",
    "def observed_agreement_for_column(df: pd.DataFrame, col: str, r1: str = R1, r2: str = R2) -> float:\n",
    "    \"\"\"Observed agreement (%) for one binary column.\"\"\"\n",
    "    y1, y2 = aligned_ratings(df, col, r1, r2)\n",
    "    if len(y1) == 0:\n",
    "        return np.nan\n",
    "    return float((y1 == y2).mean() * 100.0)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 4) Overall ISO agreement by pooling all ISO decisions\n",
    "# ----------------------------------------------------------\n",
    "def overall_iso_agreement(df: pd.DataFrame, iso_cols=ISO_COLS, r1: str = R1, r2: str = R2):\n",
    "    \"\"\"Overall kappa + observed agreement across ISO block by pooling all ISO decisions.\"\"\"\n",
    "    all_r1, all_r2 = [], []\n",
    "    for col in iso_cols:\n",
    "        y1, y2 = aligned_ratings(df, col, r1, r2)\n",
    "        all_r1.extend(y1.tolist())\n",
    "        all_r2.extend(y2.tolist())\n",
    "\n",
    "    if len(all_r1) == 0:\n",
    "        return np.nan, np.nan\n",
    "\n",
    "    kappa = cohen_kappa_score(all_r1, all_r2)\n",
    "    obs = float((np.array(all_r1) == np.array(all_r2)).mean() * 100.0)\n",
    "    return kappa, obs\n",
    "\n",
    "# -----------------------\n",
    "# 5) Run computations\n",
    "# -----------------------\n",
    "rows = []\n",
    "for col in ALL_BINARY_COLS:\n",
    "    rows.append({\n",
    "        \"Item\": col,\n",
    "        \"Cohens_Kappa\": kappa_for_column(df, col),\n",
    "        \"Observed_Agreement_%\": observed_agreement_for_column(df, col)\n",
    "    })\n",
    "\n",
    "results = pd.DataFrame(rows)\n",
    "\n",
    "iso_kappa, iso_obs = overall_iso_agreement(df)\n",
    "\n",
    "# Add overall ISO row (nice for tables)\n",
    "results = pd.concat([\n",
    "    results,\n",
    "    pd.DataFrame([{\n",
    "        \"Item\": \"Overall_ISO_FS_to_P\",\n",
    "        \"Cohens_Kappa\": iso_kappa,\n",
    "        \"Observed_Agreement_%\": iso_obs\n",
    "    }])\n",
    "], ignore_index=True)\n",
    "\n",
    "# -----------------------\n",
    "# 6) Output\n",
    "# -----------------------\n",
    "print(\"\\n=== Agreement by item (kappa + observed agreement) ===\")\n",
    "print(results.to_string(index=False))\n",
    "\n",
    "print(\"\\n=== Overall ISO (FS–P) ===\")\n",
    "print(f\"Cohen's kappa: {iso_kappa}\")\n",
    "print(f\"Observed agreement (%): {iso_obs:.2f}\")\n",
    "\n",
    "# Save outputs for replication package\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "results.to_csv(\"output/agreement_results.csv\", index=False)\n",
    "print(\"\\nSaved: output/agreement_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9450272f-4416-4112-89a0-c95ceb5f2f70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
